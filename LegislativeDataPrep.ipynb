{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Read labelled data files and build a dataframe with one data file parsed per row\n",
    "\n",
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:18:37.024416Z",
     "start_time": "2021-01-24T03:18:37.017790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/emilyng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "import pdfminer as pdfm\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "## Create list of useless_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:11:49.023759Z",
     "start_time": "2021-01-24T03:11:48.970049Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "# dont_stop = [] # Put any words that we want to keep that are in nltk_stopwords here, so we can remove them from the list\n",
    "punct_list = list(string.punctuation)\n",
    "# dont_stop_punct = []\n",
    "\n",
    "#mick_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "#             'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "#             '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'id', '2d', 'one', 'two', '3d', 'ibid'\n",
    "#            ]\n",
    "\n",
    "tmp = nltk_stopwords + punct_list # + mick_list\n",
    "useless_words = tmp\n",
    "# useless_words = tmp minus the dont* variables\n",
    "#useless_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Prep Functions\n",
    "- get text from pdf\n",
    "- clean the text (remove garbage characters)\n",
    "- filter out less useful words\n",
    "- count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:11:51.645382Z",
     "start_time": "2021-01-24T03:11:51.638300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text_from_pdf(pdf_path) :\n",
    "    output_string = StringIO()\n",
    "    with open(pdf_path, 'rb') as in_file:\n",
    "        parser = PDFParser(in_file)\n",
    "        doc = PDFDocument(parser)\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(doc):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "    return output_string.getvalue()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:24:56.206493Z",
     "start_time": "2021-01-24T03:24:56.195626Z"
    }
   },
   "outputs": [],
   "source": [
    "# This should be replaced using regular expressions and can be significantly enhanced functionally.\n",
    "# Almost a placeholder function right now, just removing newlines.\n",
    "def clean_text(input_string) :\n",
    "    str1 = input_string.replace(\" \\n\", \"\")\n",
    "    str2 = str1.replace(\"\\n\", \"\")\n",
    "    str3 = str2.replace(\"\\\\x0c\", \"\")\n",
    "    str4 = re.sub('[^A-Za-z0-9 ]+', '', str3)\n",
    "    str5 = re.sub('\\d+', '', str4)\n",
    "    final_string = str5.lower()\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:18:07.593201Z",
     "start_time": "2021-01-24T03:18:07.587522Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_words(input_words) :\n",
    "    filtered_words = []\n",
    "    for word in input_words :\n",
    "        append_it = True\n",
    "        if word in useless_words :\n",
    "            #print(f\"useless word {word}\")\n",
    "            append_it = False\n",
    "        elif len(word) == 1 :\n",
    "            #print(f\"word length 1 {word}\")\n",
    "            append_it = False    \n",
    "        elif word.isdigit() :\n",
    "            #print(f\"number {word}\")\n",
    "            append_it = False\n",
    "        elif word[0] == chr(167) :\n",
    "            #print(f\"section symbol {word}\")\n",
    "            append_it = False\n",
    "        if append_it :\n",
    "            filtered_words.append(word)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:18:08.052530Z",
     "start_time": "2021-01-24T03:18:08.043396Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(word_list) :\n",
    "    word_counter = Counter(word_list)\n",
    "    wc_rev_sort = sorted(word_counter.items(), key=lambda pair: pair[1], reverse=True)\n",
    "    return wc_rev_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:18:08.354456Z",
     "start_time": "2021-01-24T03:18:08.350088Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_bow2(words) :\n",
    "    dict = {}\n",
    "    for word in words :\n",
    "        append_it = True\n",
    "        if word in useless_words :\n",
    "            #print(f\"useless word {word}\")\n",
    "            append_it = False\n",
    "        if len(word) == 1 :\n",
    "            #print(f\"word length 1 {word}\")\n",
    "            append_it = False\n",
    "        if word.isdigit() :\n",
    "            #print(f\"number {word}\")\n",
    "            append_it = False\n",
    "        if word[0] == chr(167) :\n",
    "            #print(f\"section symbol {word}\")\n",
    "            append_it = False\n",
    "        if append_it :\n",
    "            dict[word] = 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame for ML Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:27:19.465442Z",
     "start_time": "2021-01-24T03:25:45.840527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     doc_num                               doc_filepath  \\\n",
      "0          0      Data/Environmental/PLAW-104publ70.pdf   \n",
      "1          1     Data/Environmental/PLAW-112publ177.pdf   \n",
      "2          2      Data/Environmental/PLAW-116publ63.pdf   \n",
      "3          3     Data/Environmental/PLAW-110publ288.pdf   \n",
      "4          4     Data/Environmental/PLAW-108publ425.pdf   \n",
      "..       ...                                        ...   \n",
      "134      134   Data/NonEnvironmental/PLAW-114publ38.pdf   \n",
      "135      135  Data/NonEnvironmental/PLAW-115publ281.pdf   \n",
      "136      136  Data/NonEnvironmental/PLAW-115publ280.pdf   \n",
      "137      137   Data/NonEnvironmental/PLAW-116publ52.pdf   \n",
      "138      138  Data/NonEnvironmental/PLAW-116publ107.pdf   \n",
      "\n",
      "                                              doc_text  \\\n",
      "0    PUBLIC LAW 104–70—DEC. 23, 1995\\n\\n109 STAT. 7...   \n",
      "1    PUBLIC LAW 112–177—SEPT. 28, 2012 \\n\\n126 STAT...   \n",
      "2    133 STAT. 1120 \\n\\nPUBLIC LAW 116–63—OCT. 4, 2...   \n",
      "3    PUBLIC LAW 110–288—JULY 29, 2008 \\n\\nCLEAN BOA...   \n",
      "4    PUBLIC LAW 108–425—NOV. 30, 2004\\n\\nTIJUANA RI...   \n",
      "..                                                 ...   \n",
      "134  PUBLIC LAW 114–38—JULY 28, 2015 \\n\\n129 STAT. ...   \n",
      "135  PUBLIC LAW 115–281—DEC. 1, 2018 \\n\\n132 STAT. ...   \n",
      "136  132 STAT. 4190 \\n\\nPUBLIC LAW 115–280—NOV. 29,...   \n",
      "137  133 STAT. 1076 \\n\\nPUBLIC LAW 116–52—AUG. 23, ...   \n",
      "138  133 STAT. 3292 \\n\\nPUBLIC LAW 116–107—JAN. 17,...   \n",
      "\n",
      "                                          text_cleaned  \\\n",
      "0    public law dec   stat public law th congressan...   \n",
      "1    public law sept   stat public law th congressa...   \n",
      "2     stat public law oct  public law th congressan...   \n",
      "3    public law july  clean boating act of swalcilb...   \n",
      "4    public law nov  tijuana river valley estuary a...   \n",
      "..                                                 ...   \n",
      "134  public law july   stat public law th congressa...   \n",
      "135  public law dec   stat public law th congressan...   \n",
      "136   stat public law nov  public law th congressan...   \n",
      "137   stat public law aug  public law th congressan...   \n",
      "138   stat public law jan  public law th congressan...   \n",
      "\n",
      "                                            nltk_words  \\\n",
      "0    [public, law, dec, stat, public, law, th, cong...   \n",
      "1    [public, law, sept, stat, public, law, th, con...   \n",
      "2    [stat, public, law, oct, public, law, th, cong...   \n",
      "3    [public, law, july, clean, boating, act, of, s...   \n",
      "4    [public, law, nov, tijuana, river, valley, est...   \n",
      "..                                                 ...   \n",
      "134  [public, law, july, stat, public, law, th, con...   \n",
      "135  [public, law, dec, stat, public, law, th, cong...   \n",
      "136  [stat, public, law, nov, public, law, th, cong...   \n",
      "137  [stat, public, law, aug, public, law, th, cong...   \n",
      "138  [stat, public, law, jan, public, law, th, cong...   \n",
      "\n",
      "                                        filtered_words  \\\n",
      "0    [public, law, dec, stat, public, law, th, cong...   \n",
      "1    [public, law, sept, stat, public, law, th, con...   \n",
      "2    [stat, public, law, oct, public, law, th, cong...   \n",
      "3    [public, law, july, clean, boating, act, swalc...   \n",
      "4    [public, law, nov, tijuana, river, valley, est...   \n",
      "..                                                 ...   \n",
      "134  [public, law, july, stat, public, law, th, con...   \n",
      "135  [public, law, dec, stat, public, law, th, cong...   \n",
      "136  [stat, public, law, nov, public, law, th, cong...   \n",
      "137  [stat, public, law, aug, public, law, th, cong...   \n",
      "138  [stat, public, law, jan, public, law, th, cong...   \n",
      "\n",
      "                                           word_counts  \\\n",
      "0    [(may, 4), (occupancy, 4), (vehicle, 3), (trip...   \n",
      "1    [(new, 367), (application, 239), (use, 204), (...   \n",
      "2    [(water, 19), (state, 12), (revolving, 9), (dr...   \n",
      "3    [(management, 14), (recreational, 12), (admini...   \n",
      "4    [(may, 9), (act, 7), (paragraph, 7), (law, 6),...   \n",
      "..                                                 ...   \n",
      "134  [(business, 21), (small, 12), (act, 11), (loan...   \n",
      "135  [(national, 5), (december, 4), (act, 4), (floo...   \n",
      "136  [(disaster, 3), (public, 2), (law, 2), (nov, 2...   \n",
      "137  [(act, 5), (title, 5), (aug, 4), (paid, 4), (d...   \n",
      "138  [(veterans, 12), (secretary, 9), (grant, 8), (...   \n",
      "\n",
      "                                                   bow         env_label  \n",
      "0    {'public': 1, 'law': 1, 'dec': 1, 'stat': 1, '...     Environmental  \n",
      "1    {'public': 1, 'law': 1, 'sept': 1, 'stat': 1, ...     Environmental  \n",
      "2    {'stat': 1, 'public': 1, 'law': 1, 'oct': 1, '...     Environmental  \n",
      "3    {'public': 1, 'law': 1, 'july': 1, 'clean': 1,...     Environmental  \n",
      "4    {'public': 1, 'law': 1, 'nov': 1, 'tijuana': 1...     Environmental  \n",
      "..                                                 ...               ...  \n",
      "134  {'public': 1, 'law': 1, 'july': 1, 'stat': 1, ...  NonEnvironmental  \n",
      "135  {'public': 1, 'law': 1, 'dec': 1, 'stat': 1, '...  NonEnvironmental  \n",
      "136  {'stat': 1, 'public': 1, 'law': 1, 'nov': 1, '...  NonEnvironmental  \n",
      "137  {'stat': 1, 'public': 1, 'law': 1, 'aug': 1, '...  NonEnvironmental  \n",
      "138  {'stat': 1, 'public': 1, 'law': 1, 'jan': 1, '...  NonEnvironmental  \n",
      "\n",
      "[139 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# We will populate these series\n",
    "doc_num = pd.Series([], name='doc_num', dtype='int')\n",
    "doc_filepath = pd.Series([], name='doc_filepath', dtype='str')\n",
    "doc_text = pd.Series([], name='doc_text', dtype='str')\n",
    "text_cleaned = pd.Series([], name='text_cleaned', dtype='str')\n",
    "nltk_words = pd.Series([], name='nltk_words', dtype='str')\n",
    "filtered_words = pd.Series([], name='filtered_words', dtype='str')\n",
    "word_counts = pd.Series([], name='word_counts', dtype='str')\n",
    "env_label = pd.Series([], name='env_label', dtype='str')\n",
    "bow = pd.Series([], name='bow', dtype='str')\n",
    "\n",
    "doc_ctr = 0\n",
    "\n",
    "# Process the Environmental data\n",
    "envdir = 'Data/Environmental'\n",
    "for file_nm in os.listdir(envdir) :\n",
    "    filepath = envdir + '/' + file_nm\n",
    "    doc_str = get_text_from_pdf(filepath)\n",
    "    txt_cln = clean_text(doc_str)\n",
    "    nltk_wds = nltk.word_tokenize(txt_cln)\n",
    "    filt_words = filter_words(nltk_wds)\n",
    "    wc = count_words(filt_words)\n",
    "    word_counts[doc_ctr] = wc\n",
    "    bow2 = build_bow2(filt_words)\n",
    "    \n",
    "    # break # for debugging all text cleanups\n",
    "\n",
    "    doc_num[doc_ctr] = doc_ctr\n",
    "    doc_filepath[doc_ctr] = filepath\n",
    "    doc_text[doc_ctr] = doc_str\n",
    "    text_cleaned[doc_ctr] = txt_cln\n",
    "    nltk_words[doc_ctr] = nltk_wds\n",
    "    filtered_words[doc_ctr] = filt_words\n",
    "    env_label[doc_ctr] = 'Environmental'\n",
    "    bow[doc_ctr] = bow2\n",
    "    doc_ctr += 1\n",
    "\n",
    "# Process the Non-Environmental Data - same loop, should get into a function later\n",
    "envdir = 'Data/NonEnvironmental'\n",
    "for file_nm in os.listdir(envdir) :\n",
    "    filepath = envdir + '/' + file_nm\n",
    "    doc_str = get_text_from_pdf(filepath)\n",
    "    txt_cln = clean_text(doc_str)\n",
    "    nltk_wds = nltk.word_tokenize(txt_cln)\n",
    "    filt_words = filter_words(nltk_wds)\n",
    "    wc = count_words(filt_words)\n",
    "    word_counts[doc_ctr] = wc\n",
    "    bow2 = build_bow2(filt_words)\n",
    "\n",
    "    doc_num[doc_ctr] = doc_ctr\n",
    "    doc_filepath[doc_ctr] = filepath\n",
    "    doc_text[doc_ctr] = doc_str\n",
    "    text_cleaned[doc_ctr] = txt_cln\n",
    "    nltk_words[doc_ctr] = nltk_wds\n",
    "    filtered_words[doc_ctr] = filt_words\n",
    "    env_label[doc_ctr] = 'NonEnvironmental'\n",
    "    bow[doc_ctr] = bow2\n",
    "    doc_ctr += 1\n",
    "\n",
    "# Assemble the final data frame\n",
    "doc_df = doc_num.to_frame().\\\n",
    "         join(doc_filepath).\\\n",
    "         join(doc_text).\\\n",
    "         join(text_cleaned).\\\n",
    "         join(nltk_words).\\\n",
    "         join(filtered_words).\\\n",
    "         join(word_counts).\\\n",
    "         join(bow).\\\n",
    "         join(env_label)\n",
    "print(doc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:28:03.299813Z",
     "start_time": "2021-01-24T03:28:03.288960Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'133 STAT. 3292 \\n\\nPUBLIC LAW 116–107—JAN. 17, 2020 \\n\\nPublic Law 116–107 \\n116th Congress \\n\\nAn Act \\n\\nJan. 17, 2020 \\n\\n[H.R. 2385] \\n\\nTo permit the Secretary of Veterans Affairs to establish a grant program to conduct \\ncemetery  research  and  produce  educational  materials  for  the  Veterans  Legacy \\nProgram. \\n\\nBe  it  enacted  by  the  Senate  and  House  of  Representatives  of \\n\\nthe United States of America in Congress assembled, \\n\\n38 USC 2400 \\nnote. \\n\\nSECTION  1.  GRANTS  FOR  CEMETERY  RESEARCH  AND  THE  PRODUC-\\n\\nTION OF EDUCATIONAL MATERIALS. \\n\\n(a) GRANTS AUTHORIZED.— \\n\\n(1)  IN GENERAL.—The  Secretary  of  Veterans  Affairs  may \\nestablish  a  grant  program  to  conduct  cemetery  research  and \\nproduce  educational  materials  for  the  Veterans  Legacy  Pro-\\ngram. \\n\\n(2)  ELIGIBLE RECIPIENTS.—The  Secretary  may  award  a \\n\\ngrant under this section to any of the following entities: \\n(A) An institution of higher learning. \\n(B) A local education agency. \\n(C)  A  non-profit  entity  that  the  Secretary  determines \\n\\nhas a demonstrated history of community engagement. \\n\\n(D)  Another  recipient  the  Secretary  determines  to  be \\n\\nappropriate. \\n(3) USE OF FUNDS.—A recipient of a grant under this section \\n\\nmay use the grant amount to— \\n\\n(A)  conduct  research  related  to  national,  State,  or \\n\\nTribal veterans’ cemeteries; \\n\\n(B)  produce  education  materials  that  teach  about  the \\nhistory  of  veterans  interred  in  national,  State,  or  Tribal \\nveterans’ cemeteries; and \\n\\n(C) promote community engagement with the histories \\nof  veterans  interred  in  national,  State,  or  Tribal  veterans’ \\ncemeteries. \\n(4) MAXIMUM AMOUNT.—A grant awarded under this section \\n\\nmay not exceed $500,000. \\n(b) REGULATIONS.—If the Secretary establishes a grant program \\nunder  this  section,  the  Secretary  shall  prescribe  regulations \\nregarding— \\n\\n(1)  the  evaluation  of  applications  for  grants  under  the \\n\\nprogram; and \\n\\n(2) administration of the program. \\n\\n(c)  REPORT REQUIRED.—Not  later  than  2  years  after  the  Sec-\\nretary establishes a grant program under this section, the Secretary \\nshall  submit  to  the  committees  on  Veterans’  Affairs  of  the  House \\n\\nDeterminations. \\n\\nEvaluation. \\n\\nDetermination. \\n\\n \\n\\nF\\nD\\nP\\nS\\nW\\nA\\nL\\n \\nB\\nU\\nP\\n \\nh\\nt\\ni\\n\\n \\n\\nw\\nD\\nO\\nR\\nP\\n2\\n8\\n0\\nR\\n0\\n2\\n5\\nP\\nA\\nL\\n \\nn\\no\\n \\ny\\nn\\na\\nb\\na\\nR\\n\\nl\\n\\nVerDate Sep 11 2014  06:11 Feb 04, 2020 Jkt 099139 PO 00107 Frm 00001 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL107.116 PUBL107\\n\\n\\x0cPUBLIC LAW 116–107—JAN. 17, 2020 \\n\\n133 STAT. 3293 \\n\\nof Representatives and the Senate a report regarding the determina-\\ntion  of  the  Secretary  whether  the  grant  program  is  a  financially \\neffective means to promote the purposes in subsection (a)(3). \\n\\n(d) DEFINITIONS.—In this section: \\n\\n(1)  The  term  ‘‘Veterans  Legacy  Program’’  means  the  pro-\\ngram  of  the  National  Cemetery  Administration  that  is  respon-\\nsible  for  providing  engagement  and  educational  tools  and \\nopportunities  to  the  public  regarding  the  service  and  sacrifice \\nof veterans interred in national, State, or Tribal veterans’ ceme-\\nteries. \\n\\n(2)  The  term  ‘‘institution  of  higher  learning’’  has  the \\nmeaning  given  that  term  in  section  3452(f)  of  title  38,  United \\nStates Code. \\n\\n(3)  The  term  ‘‘local  educational  agency’’  has  the  meaning \\ngiven  that  term  in  section  8101  of  the  Elementary  and  Sec-\\nondary Education Act of 1965 (20 U.S.C. 7801). \\n\\nApproved January 17, 2020. \\n\\nLEGISLATIVE HISTORY—H.R. 2385: \\n\\nHOUSE REPORTS: No. 116–179 (Comm. on Veterans’ Affairs). \\nCONGRESSIONAL RECORD, Vol. 165 (2019): \\n\\nOct. 15, considered and passed House. \\nDec. 19, considered and passed Senate. \\n\\nÆ \\n\\n \\n\\nF\\nD\\nP\\nS\\nW\\nA\\nL\\n \\nB\\nU\\nP\\n \\nh\\nt\\ni\\n\\n \\n\\nw\\nD\\nO\\nR\\nP\\n2\\n8\\n0\\nR\\n0\\n2\\n5\\nP\\nA\\nL\\n \\nn\\no\\n \\ny\\nn\\na\\nb\\na\\nR\\n\\nl\\n\\nVerDate Sep 11 2014  06:11 Feb 04, 2020 Jkt 099139 PO 00107 Frm 00002 Fmt 6580 Sfmt 6580 E:\\\\PUBLAW\\\\PUBL107.116 PUBL107\\n\\n\\x0c'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:27:48.502186Z",
     "start_time": "2021-01-24T03:27:48.488379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' stat public law jan  public law th congressan actjan  hr to permit the secretary of veterans affairs to establish a grant program to conductcemetery  research  and  produce  educational  materials  for  the  veterans  legacyprogrambe  it  enacted  by  the  senate  and  house  of  representatives  ofthe united states of america in congress assembled usc notesection    grants  for  cemetery  research  and  the  production of educational materialsa grants authorized  in generalthe  secretary  of  veterans  affairs  mayestablish  a  grant  program  to  conduct  cemetery  research  andproduce  educational  materials  for  the  veterans  legacy  program  eligible recipientsthe  secretary  may  award  agrant under this section to any of the following entitiesa an institution of higher learningb a local education agencyc  a  nonprofit  entity  that  the  secretary  determineshas a demonstrated history of community engagementd  another  recipient  the  secretary  determines  to  beappropriate use of fundsa recipient of a grant under this sectionmay use the grant amount toa  conduct  research  related  to  national  state  ortribal veterans cemeteriesb  produce  education  materials  that  teach  about  thehistory  of  veterans  interred  in  national  state  or  tribalveterans cemeteries andc promote community engagement with the historiesof  veterans  interred  in  national  state  or  tribal  veteranscemeteries maximum amounta grant awarded under this sectionmay not exceed b regulationsif the secretary establishes a grant programunder  this  section  the  secretary  shall  prescribe  regulationsregarding  the  evaluation  of  applications  for  grants  under  theprogram and administration of the programc  report requirednot  later  than    years  after  the  secretary establishes a grant program under this section the secretaryshall  submit  to  the  committees  on  veterans  affairs  of  the  housedeterminationsevaluationdeterminationfdpswalbuphtiwdorprpalnoynabarlverdate sep     feb   jkt  po  frm  fmt  sfmt  epublawpubl publpublic law jan   stat of representatives and the senate a report regarding the determination  of  the  secretary  whether  the  grant  program  is  a  financiallyeffective means to promote the purposes in subsection ad definitionsin this section  the  term  veterans  legacy  program  means  the  program  of  the  national  cemetery  administration  that  is  responsible  for  providing  engagement  and  educational  tools  andopportunities  to  the  public  regarding  the  service  and  sacrificeof veterans interred in national state or tribal veterans cemeteries  the  term  institution  of  higher  learning  has  themeaning  given  that  term  in  section  f  of  title    unitedstates code  the  term  local  educational  agency  has  the  meaninggiven  that  term  in  section    of  the  elementary  and  secondary education act of   usc approved january  legislative historyhr house reports no  comm on veterans affairscongressional record vol  oct  considered and passed housedec  considered and passed senatefdpswalbuphtiwdorprpalnoynabarlverdate sep     feb   jkt  po  frm  fmt  sfmt  epublawpubl publ'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_cln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And write it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:27:59.380216Z",
     "start_time": "2021-01-24T03:27:56.382476Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_df.to_csv(\"Data/doc_list1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
